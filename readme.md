# ğŸ§  ASL Sign Language Detection Using Deep Learning

> **Internship Project â€“ Unified Mentor Pvt Ltd**  
> *Intern: [Rudraksh Sachdeva]*  
> *Internship Duration: [10-06-2025] to [10-07-2025]*  
> *GitHub Repository: [https://github.com/Rudrakshsachdev/asl-sign-language-detection.git]*

---

## ğŸ“Œ Overview

This project focuses on the **real-time detection of American Sign Language (ASL) alphabets** using a webcam and a Convolutional Neural Network (CNN). It aims to bridge communication gaps between the hearing-impaired and the general public. The system recognizes hand gestures corresponding to letters A-Z, plus 'space', 'delete', and 'nothing', and converts them into readable text on screen â€” with optional **text-to-speech functionality**.

---

## ğŸ¯ Objective

- Build a machine learning model that can classify ASL hand gestures in real-time.
- Design a system to predict characters and form readable sentences.
- Enhance accessibility using TTS (Text-To-Speech) for audio output.

---

## ğŸ§  Key Features

- ğŸ“· Real-time webcam integration using OpenCV  
- ğŸ§  CNN-based classifier trained on a labeled ASL dataset  
- ğŸ—£ï¸ Converts predicted characters into spoken words using pyttsx3  
- ğŸ“„ Modular, maintainable code with clear documentation  
- ğŸ“Š Model achieves high accuracy (~99.7% on validation data)

---

## ğŸ—‚ï¸ Project Structure

ASL_Sign_Detection_Project/
â”œâ”€â”€ data/ # ASL dataset (excluded in GitHub)
â”‚ â””â”€â”€ rawData/
â”‚ â””â”€â”€ asl_alphabet_train/
â”œâ”€â”€ src/ # Source scripts
â”‚ â”œâ”€â”€ Preprocessing.py # Data loading and preprocessing
â”‚ â”œâ”€â”€ TrainModel.py # CNN model building and training
â”‚ â”œâ”€â”€ EvaluateModel.py # Model performance evaluation
â”‚ â”œâ”€â”€ RealTimeASL.py # Real-time ASL detection and sentence building
â”‚ â””â”€â”€ models/
â”‚ â””â”€â”€ asl_model.h5 # Saved trained model
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ LICENSE # MIT License
â””â”€â”€ README.md # You are here


---

## ğŸ§ª Dataset

- **Dataset**: [ASL Alphabet Dataset from Kaggle](https://www.kaggle.com/datasets/grassknoted/asl-alphabet)
- **Format**: Image folders per alphabet (e.g., `A/`, `B/`, ..., `space/`)
- **Size**: ~87,000 images, 200x200 resolution
- ğŸ“Œ *Place the dataset inside:*


---

## ğŸ§° Technologies Used

| Technology | Purpose |
|------------|---------|
| **Python 3.10** | Programming language |
| **TensorFlow / Keras** | Deep learning model |
| **OpenCV** | Image capture & processing |
| **NumPy** | Numerical operations |
| **scikit-learn** | Data splitting |
| **pyttsx3** | Text-to-speech synthesis |

---

## âš™ï¸ Setup Instructions

1. Clone the Repository
git clone https://github.com/your-username/asl-sign-language-detection.git
cd asl-sign-language-detection

2. Create Virtual Environment (Optional)
python -m venv .venv
.venv\Scripts\activate (for Windows)

3. Install Dependencies
pip install -r requirements.txt

4. Prepare the Dataset
Download dataset from Kaggle and extract it to:
data/rawData/asl_alphabet_train/

---

## Run the Project
Step 1: Preprocess Dataset
python src/Preprocessing.py

Step 2: Train the Model
python src/TrainModel.py

Step 3: Evaluate the Model
python src/EvaluateModel.py

Step 4: Run Real-Time Detection with TTS
python src/DetectSign.py

---

## Model Architecture
The CNN model contains the following layers:

1. 3Ã— Conv2D + MaxPooling2D

2. Flatten

3. Dense layers with ReLU activations

4. Final output layer with softmax for 29-class classification

---

## Performance
1. Validation Accuracy: ~99.71%
2. Loss: ~0.0122
3. Real-time FPS: ~10â€“15 FPS (system-dependent)

---

## Sentence & Text-to-Speech
1. System constructs a sentence from recognized characters.

2. If a gesture is held for a few seconds, it is added to the sentence.

3. Press Enter to trigger pyttsx3 to speak the constructed sentence.

---

## Advanced Features (Implemented)
âœ… Real-time sentence formation

âœ… Text-to-speech support

âœ… Timer-based gesture detection

---

## Future Enhancements
1. Deploy as a Flask or Streamlit web app

2. Integrate mobile camera APIs

3. Use MobileNet or EfficientNet for better accuracy

4. Include ASL word recognition

